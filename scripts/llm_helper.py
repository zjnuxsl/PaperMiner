"""
LLM è¾…åŠ©æ¨¡å—
ç”¨äºè°ƒç”¨ Deepseek API è¿›è¡Œè®ºæ–‡ç« èŠ‚æå–
"""

import os
import json
import requests
from pathlib import Path
from typing import Dict, Optional, List
from dotenv import load_dotenv


class LLMHelper:
    """LLM è¾…åŠ©ç±»ï¼Œä½¿ç”¨ Deepseek API"""

    def __init__(self, model_name: str = "deepseek"):
        """
        åˆå§‹åŒ– LLM Helper

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œç›®å‰ä»…æ”¯æŒ "deepseek"
        """
        self.model_name = model_name.lower()

        # åŠ è½½ .env æ–‡ä»¶
        env_path = Path(__file__).parent.parent / ".env"
        load_dotenv(env_path)

        # è·å– API é…ç½®
        if self.model_name == "deepseek":
            self.api_key = os.getenv("DEEPSEEK_API_KEY")
            self.api_endpoint = "https://api.deepseek.com/v1/chat/completions"
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}ï¼Œç›®å‰ä»…æ”¯æŒ 'deepseek'")

        if not self.api_key:
            raise ValueError(f"æœªæ‰¾åˆ° DEEPSEEK API Keyï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
    
    def call_llm(self, prompt: str, max_tokens: int = 4000, temperature: float = 0.1,
                  max_retries: int = 3, verbose: bool = True, json_mode: bool = False) -> Optional[str]:
        """è°ƒç”¨ LLM APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            prompt: æç¤ºè¯
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: æ¸©åº¦å‚æ•°ï¼ˆè¶Šä½è¶Šç¡®å®šï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            json_mode: æ˜¯å¦å¯ç”¨ç»“æ„åŒ– JSON è¾“å‡ºï¼ˆä»… Deepseek æœ‰æ•ˆï¼‰

        Returns:
            LLM è¿”å›çš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
        """
        import time

        # æ˜¾ç¤ºè¯·æ±‚ä¿¡æ¯
        if verbose:
            prompt_length = len(prompt)
            estimated_tokens = prompt_length // 4  # ç²—ç•¥ä¼°è®¡ï¼š4 å­—ç¬¦ â‰ˆ 1 token
            print(f"    ğŸ“Š è¯·æ±‚ä¿¡æ¯:")
            print(f"       - æç¤ºè¯é•¿åº¦: {prompt_length:,} å­—ç¬¦")
            print(f"       - ä¼°è®¡ Token æ•°: ~{estimated_tokens:,} tokens")
            print(f"       - æœ€å¤§è¿”å› Token: {max_tokens:,} tokens")
            print(f"       - æ¸©åº¦å‚æ•°: {temperature}")
            print(f"       - API ç«¯ç‚¹: {self.model_name.upper()}")

        for attempt in range(max_retries):
            try:
                start_time = time.time()

                if verbose and attempt > 0:
                    print(f"    ğŸ”„ ç¬¬ {attempt + 1} æ¬¡å°è¯•...")

                # è°ƒç”¨ Deepseek APIï¼ˆå¯ç”¨ JSON æ¨¡å¼å¦‚æœéœ€è¦ï¼‰
                result = self._call_deepseek(prompt, max_tokens, temperature, json_mode=json_mode)

                elapsed_time = time.time() - start_time

                # æ˜¾ç¤ºå“åº”ä¿¡æ¯
                if verbose and result:
                    response_length = len(result)
                    estimated_response_tokens = response_length // 4
                    print(f"    âœ… å“åº”ä¿¡æ¯:")
                    print(f"       - å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")
                    print(f"       - å“åº”é•¿åº¦: {response_length:,} å­—ç¬¦")
                    print(f"       - ä¼°è®¡ Token æ•°: ~{estimated_response_tokens:,} tokens")

                return result

            except requests.exceptions.Timeout:
                elapsed_time = time.time() - start_time
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5  # 5ç§’, 10ç§’, 15ç§’
                    print(f"    âš ï¸  API è°ƒç”¨è¶…æ—¶ï¼ˆ{elapsed_time:.1f} ç§’ï¼‰ï¼Œ{wait_time} ç§’åé‡è¯•ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰...")
                    time.sleep(wait_time)
                else:
                    print(f"    âŒ API è°ƒç”¨è¶…æ—¶ï¼ˆ{elapsed_time:.1f} ç§’ï¼‰ï¼Œå·²é‡è¯• {max_retries} æ¬¡ï¼Œæ”¾å¼ƒ")
                    return None
            except Exception as e:
                elapsed_time = time.time() - start_time
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3  # 3ç§’, 6ç§’, 9ç§’
                    print(f"    âš ï¸  LLM è°ƒç”¨å¤±è´¥ï¼ˆ{elapsed_time:.1f} ç§’ï¼‰: {str(e)}ï¼Œ{wait_time} ç§’åé‡è¯•ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡ï¼‰...")
                    time.sleep(wait_time)
                else:
                    print(f"    âŒ LLM è°ƒç”¨å¤±è´¥ï¼ˆ{elapsed_time:.1f} ç§’ï¼‰: {str(e)}")
                    return None

        return None

    def _call_deepseek(self, prompt: str, max_tokens: int, temperature: float,
                        json_mode: bool = False) -> Optional[str]:
        """è°ƒç”¨ Deepseek API"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        data = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": max_tokens,
            "temperature": temperature
        }

        # å½“éœ€è¦ç»“æ„åŒ– JSON è¾“å‡ºæ—¶ï¼Œå¯ç”¨ Deepseek çš„ JSON Output åŠŸèƒ½
        if json_mode:
            data["response_format"] = {"type": "json_object"}

        # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 120 ç§’ï¼ˆå¤„ç†é•¿æ–‡æ¡£ï¼‰
        response = requests.post(self.api_endpoint, headers=headers, json=data, timeout=120)
        response.raise_for_status()

        result = response.json()

        # æ˜¾ç¤º API ä½¿ç”¨ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if "usage" in result:
            usage = result["usage"]
            print(f"    ğŸ“ˆ API ä½¿ç”¨ç»Ÿè®¡:")
            if "prompt_tokens" in usage:
                print(f"       - è¾“å…¥ Token: {usage['prompt_tokens']:,}")
            if "completion_tokens" in usage:
                print(f"       - è¾“å‡º Token: {usage['completion_tokens']:,}")
            if "total_tokens" in usage:
                print(f"       - æ€»è®¡ Token: {usage['total_tokens']:,}")

            # ä¼°ç®—æˆæœ¬ï¼ˆDeepseek ä»·æ ¼ï¼šè¾“å…¥ Â¥0.001/1K tokensï¼Œè¾“å‡º Â¥0.002/1K tokensï¼‰
            if "prompt_tokens" in usage and "completion_tokens" in usage:
                input_cost = usage["prompt_tokens"] / 1000 * 0.001
                output_cost = usage["completion_tokens"] / 1000 * 0.002
                total_cost = input_cost + output_cost
                print(f"       - ä¼°ç®—æˆæœ¬: Â¥{total_cost:.4f} (è¾“å…¥: Â¥{input_cost:.4f}, è¾“å‡º: Â¥{output_cost:.4f})")

        # æå–ç”Ÿæˆçš„æ–‡æœ¬
        if "choices" in result and len(result["choices"]) > 0:
            choice = result["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]

        return None

    def extract_sections(self, markdown_content: str, prompt_template: str,
                        missing_sections: Optional[List[str]] = None) -> Optional[Dict[str, str]]:
        """ä½¿ç”¨ LLM æå–è®ºæ–‡ç« èŠ‚

        Args:
            markdown_content: å®Œæ•´çš„ Markdown æ–‡æ¡£å†…å®¹
            prompt_template: æç¤ºè¯æ¨¡æ¿
            missing_sections: éœ€è¦æå–çš„ç« èŠ‚åˆ—è¡¨ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™æå–æ‰€æœ‰ç« èŠ‚ï¼‰

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºç« èŠ‚åç§°ï¼Œå€¼ä¸ºç« èŠ‚å†…å®¹
            ä¾‹å¦‚: {"Abstract": "...", "Introduction": "...", ...}
        """
        # æ„å»ºå®Œæ•´æç¤ºè¯
        full_prompt = prompt_template.replace("{MARKDOWN_CONTENT}", markdown_content)

        # å¦‚æœæŒ‡å®šäº†ç¼ºå¤±ç« èŠ‚ï¼Œæ›¿æ¢å ä½ç¬¦
        if missing_sections and "{TARGET_SECTIONS_LIST}" in full_prompt:
            sections_list = "\n".join([f"- **{section}**" for section in missing_sections])
            full_prompt = full_prompt.replace("{TARGET_SECTIONS_LIST}", sections_list)

        # è°ƒç”¨ LLMï¼ˆå¯ç”¨ JSON æ¨¡å¼ï¼Œä»¥æé«˜è§£ææˆåŠŸç‡ï¼‰
        json_mode = True

        # æ ¹æ®è¯·æ±‚çš„ç« èŠ‚æ•°é‡åŠ¨æ€è°ƒæ•´ max_tokens
        # å¦‚æœåªè¯·æ±‚å°‘æ•°ç« èŠ‚ï¼Œä½¿ç”¨è¾ƒå¤§çš„ max_tokens ä»¥é¿å…æˆªæ–­
        if missing_sections and len(missing_sections) == 1:
            max_tokens = 8000  # å•ä¸ªç« èŠ‚å¯èƒ½å¾ˆé•¿ï¼Œç»™è¶³ç©ºé—´
        elif missing_sections and len(missing_sections) <= 3:
            max_tokens = 10000  # 2-3 ä¸ªç« èŠ‚ç”¨ 10000 tokens
        elif missing_sections and len(missing_sections) <= 5:
            max_tokens = 12000  # 4-5 ä¸ªç« èŠ‚ç”¨ 12000 tokens
        else:
            max_tokens = 16000  # å…¨éƒ¨ç« èŠ‚ç”¨ 16000 tokens

        response = self.call_llm(full_prompt, max_tokens=max_tokens, temperature=0.1, json_mode=json_mode)

        if not response:
            return None

        # è§£æ LLM è¿”å›çš„ JSON
        try:
            # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢«åŒ…è£¹åœ¨ ```json ... ``` ä¸­ï¼‰
            response = response.strip()

            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            if response.startswith("```json"):
                response = response[7:]
            elif response.startswith("```"):
                response = response[3:]

            if response.endswith("```"):
                response = response[:-3]

            response = response.strip()

            # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é”™è¯¯
            # 1. ä¿®å¤æœªè½¬ä¹‰çš„åæ–œæ ï¼ˆLaTeX å…¬å¼ä¸­å¸¸è§ï¼‰
            # å°† \xxx æ›¿æ¢ä¸º \\xxxï¼ˆä½†ä¸å½±å“å·²ç»è½¬ä¹‰çš„ \\xxxï¼‰
            import re
            # ä½¿ç”¨è´Ÿå‘åé¡¾æ–­è¨€ï¼Œåªæ›¿æ¢å•ä¸ªåæ–œæ 
            response = re.sub(r'(?<!\\)\\(?!["\\/bfnrtu])', r'\\\\', response)

            # 2. ä¿®å¤æœªè½¬ä¹‰çš„åŒå¼•å·ï¼ˆåœ¨å­—ç¬¦ä¸²ä¸­ï¼‰
            # è¿™ä¸ªæ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶è·³è¿‡ï¼Œå› ä¸ºå¯èƒ½è¯¯ä¼¤

            # è§£æ JSON
            sections = json.loads(response)

            return sections

        except json.JSONDecodeError as e:
            print(f"    âŒ JSON è§£æå¤±è´¥: {str(e)}")
            # å°†å®Œæ•´å“åº”ä¿å­˜åˆ°è°ƒè¯•æ–‡ä»¶ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜
            try:
                from pathlib import Path
                debug_dir = Path("output") / "debug"
                debug_dir.mkdir(parents=True, exist_ok=True)
                debug_file = debug_dir / "llm_section_response.json"
                debug_file.write_text(response, encoding="utf-8")
                print(f"    ğŸ“ å·²ä¿å­˜å®Œæ•´ LLM å“åº”åˆ°: {debug_file}")
            except Exception as save_err:
                print(f"    âš ï¸ æ— æ³•ä¿å­˜ LLM å“åº”: {save_err}")
            print(f"    ğŸ“„ LLM è¿”å›å†…å®¹ï¼ˆå‰ 500 å­—ç¬¦ï¼‰: {response[:500]}...")

            # å°è¯•ä¿®å¤æˆªæ–­çš„ JSON
            if "Unterminated string" in str(e):
                print(f"    ğŸ”§ æ£€æµ‹åˆ°å­—ç¬¦ä¸²æœªé—­åˆï¼Œå°è¯•ä¿®å¤æˆªæ–­çš„ JSON...")
                try:
                    # å°è¯•é—­åˆå­—ç¬¦ä¸²å’Œ JSON å¯¹è±¡
                    fixed_response = response.rstrip()
                    # å¦‚æœæœ€åæ²¡æœ‰å¼•å·ï¼Œæ·»åŠ å¼•å·
                    if not fixed_response.endswith('"'):
                        fixed_response += '"'
                    # å¦‚æœæœ€åæ²¡æœ‰é—­åˆå¤§æ‹¬å·ï¼Œæ·»åŠ å¤§æ‹¬å·
                    if not fixed_response.endswith('}'):
                        fixed_response += '\n}'

                    sections = json.loads(fixed_response)
                    print(f"    âœ… ä¿®å¤æˆåŠŸï¼æå–åˆ° {len(sections)} ä¸ªç« èŠ‚ï¼ˆå†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼‰")
                    print(f"    âš ï¸  æ³¨æ„ï¼šç”±äº LLM è¾“å‡ºè¢«æˆªæ–­ï¼Œç« èŠ‚å†…å®¹å¯èƒ½ä¸å®Œæ•´")
                    return sections
                except Exception as fix_err:
                    print(f"    âŒ ä¿®å¤å¤±è´¥: {str(fix_err)}")

            # å°è¯•ä½¿ç”¨æ›´å®½æ¾çš„è§£ææ–¹æ³•
            try:
                print(f"    ğŸ”„ å°è¯•ä½¿ç”¨å®½æ¾æ¨¡å¼è§£æ...")
                # ä½¿ç”¨ ast.literal_evalï¼ˆæ›´å®½æ¾ï¼‰
                import ast
                sections = ast.literal_eval(response)
                print(f"    âœ… å®½æ¾æ¨¡å¼è§£ææˆåŠŸ")
                return sections
            except Exception as e2:
                print(f"    âŒ å®½æ¾æ¨¡å¼ä¹Ÿå¤±è´¥: {str(e2)}")
                return None


    def classify_section_titles(self, unrecognized_headers: List[tuple]) -> Optional[Dict[str, str]]:
        """ä½¿ç”¨ LLM å¯¹æœªè¯†åˆ«çš„ç« èŠ‚æ ‡é¢˜è¿›è¡Œåˆ†ç±»

        Args:
            unrecognized_headers: æœªè¯†åˆ«çš„æ ‡é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ (line_index, header_text, header_level)

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºæ ‡é¢˜æ–‡æœ¬ï¼Œå€¼ä¸ºç« èŠ‚ç±»å‹ï¼ˆAbstract/Introduction/Methods/Results/Discussion/Conclusionï¼‰
            å¦‚æœåˆ†ç±»å¤±è´¥è¿”å› None
        """
        if not unrecognized_headers:
            return {}

        # æ„å»ºæç¤ºè¯
        headers_text = "\n".join([f"{i+1}. {header}" for i, (_, header, _) in enumerate(unrecognized_headers)])

        prompt = f"""You are an expert in analyzing research paper structures.

I have extracted some section headers from a research paper, but I cannot determine which standard section type they belong to.

Please classify each header into ONE of these standard section types:
- Abstract
- Introduction (background, motivation, related work, literature review, preliminaries, problem statement, objectives, context, scope, theoretical background)
- Methods (methodology, experimental setup, materials, model, modelling, algorithm, classification, formulation, approach, framework, implementation, design, architecture, simulation, numerical methods, data collection, procedures, computational methods, proposed method, system design)
- Results (findings, evaluation, experiments, verification, validation, performance, comparison, analysis, data analysis, experimental results, simulation results, numerical results, observations, benchmarking, case study, application)
- Discussion (analysis, interpretation, implications, comparative analysis)
- Conclusion (summary, future work, concluding remarks, outlook, perspectives, contributions, final remarks)

**Important classification rules**:
1. **Paper title** (usually the first header) â†’ "Unknown"
2. **Article Info**, **Nomenclature**, **Acknowledgements**, **References**, **Appendix**, **Funding**, **Ethics** â†’ "Unknown"
3. **Classification**, **Modelling**, **Model**, **Algorithm**, **Framework**, **Formulation**, **Implementation**, **Design**, **Simulation**, **Proposed Method** â†’ "Methods"
4. **Verification**, **Validation**, **Evaluation**, **Comparison**, **Experiments**, **Performance**, **Benchmark**, **Case Study**, **Application** â†’ "Results"
5. **Analysis**, **Interpretation**, **Implications** â†’ "Discussion" (but "Data Analysis" â†’ "Results")
6. **Summary**, **Future Work**, **Outlook**, **Perspectives**, **Contributions** â†’ "Conclusion"
7. If a header contains numbered sections (e.g., "2. Classification", "3. Modelling"), classify based on the content, not the number
8. If uncertain, use "Unknown"

Headers to classify:
{headers_text}

Return ONLY a JSON object mapping each header number to its section type.

Example output format:
{{
  "1": "Unknown",
  "2": "Methods",
  "3": "Methods",
  "4": "Results"
}}

Your response (JSON only):"""

        print(f"    ğŸ¤– ä½¿ç”¨ LLM å¯¹ {len(unrecognized_headers)} ä¸ªæœªè¯†åˆ«æ ‡é¢˜è¿›è¡Œåˆ†ç±»...")

        # è°ƒç”¨ LLMï¼ˆå¯ç”¨ JSON æ¨¡å¼ï¼Œä½¿ç”¨è¾ƒå°çš„ max_tokensï¼‰
        json_mode = (self.model_name == "deepseek")
        response = self.call_llm(prompt, max_tokens=500, temperature=0.1, json_mode=json_mode, verbose=False)

        if not response:
            print(f"    âŒ LLM åˆ†ç±»å¤±è´¥")
            return None

        # è§£æ JSON
        try:
            # æ¸…ç†å“åº”
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.startswith("```"):
                response = response[3:]
            if response.endswith("```"):
                response = response[:-3]
            response = response.strip()

            classification = json.loads(response)

            # å°†æ•°å­—ç´¢å¼•æ˜ å°„å›æ ‡é¢˜æ–‡æœ¬
            result = {}
            for i, (_, header, _) in enumerate(unrecognized_headers):
                key = str(i + 1)
                if key in classification:
                    section_type = classification[key]
                    if section_type != "Unknown":
                        result[header] = section_type
                        print(f"       âœ“ {header[:50]}... â†’ {section_type}")

            print(f"    âœ… æˆåŠŸåˆ†ç±» {len(result)} ä¸ªæ ‡é¢˜")
            return result

        except Exception as e:
            print(f"    âŒ è§£æåˆ†ç±»ç»“æœå¤±è´¥: {str(e)}")
            return None


    def extract_sections_fallback(self, markdown_content: str, return_unrecognized: bool = False):
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å›é€€æ–¹æ³•æå–è®ºæ–‡ç« èŠ‚ï¼ˆå½“ LLM å¤±è´¥æ—¶ï¼‰

        Args:
            markdown_content: å®Œæ•´çš„ Markdown æ–‡æ¡£å†…å®¹
            return_unrecognized: æ˜¯å¦è¿”å›æœªè¯†åˆ«çš„ç« èŠ‚æ ‡é¢˜ä¿¡æ¯

        Returns:
            å¦‚æœ return_unrecognized=False: è¿”å›å­—å…¸ï¼Œé”®ä¸ºç« èŠ‚åç§°ï¼Œå€¼ä¸ºç« èŠ‚å†…å®¹
            å¦‚æœ return_unrecognized=True: è¿”å›å…ƒç»„ (sections_dict, unrecognized_headers)
                unrecognized_headers æ˜¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ (line_index, header_text, header_level)
        """
        import re

        print(f"    ğŸ”„ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å›é€€æ–¹æ³•...")

        lines = markdown_content.split('\n')
        sections = {}
        unrecognized_headers = []  # å­˜å‚¨æœªè¯†åˆ«çš„ç« èŠ‚æ ‡é¢˜

        # å®šä¹‰éœ€è¦æ’é™¤çš„ç« èŠ‚ï¼ˆè®ºæ–‡æœ«å°¾çš„è‡´è°¢ã€èµ„åŠ©ã€å£°æ˜ã€å‚è€ƒæ–‡çŒ®ç­‰ï¼‰
        exclude_patterns = [
            # æœ‰ # æ ‡è®°çš„æ ¼å¼
            r'^#+\s*acknowledgements?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*acknowledgements?\s*$',
            r'^#+\s*funding\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*funding\s*$',
            r'^#+\s*declarations?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*declarations?\s*$',
            r'^#+\s*references?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*references?\s*$',
            r'^#+\s*appendix\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*appendix\s*$',
            r'^#+\s*appendices\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*appendices\s*$',
            r'^#+\s*bibliography\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*bibliography\s*$',
            r'^#+\s*competing\s+interests?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*competing\s+interests?\s*$',
            r'^#+\s*author\s+contributions?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*author\s+contributions?\s*$',
            r'^#+\s*data\s+availability\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*data\s+availability\s*$',
            # æ–°å¢ï¼šæ›´å¤šæ’é™¤æ¨¡å¼
            r'^#+\s*conflict\s+of\s+interests?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*conflict\s+of\s+interests?\s*$',
            r'^#+\s*ethics\s+(statement|declarations?)\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*ethics\s+(statement|declarations?)\s*$',
            r'^#+\s*consent\s+(for\s+publication|to\s+participate)\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*consent\s+(for\s+publication|to\s+participate)\s*$',
            r'^#+\s*availability\s+of\s+data\s+and\s+materials?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*availability\s+of\s+data\s+and\s+materials?\s*$',
            r'^#+\s*supplementary\s+(materials?|information)\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*supplementary\s+(materials?|information)\s*$',
            r'^#+\s*abbreviations?\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*abbreviations?\s*$',
            r'^#+\s*nomenclature\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*nomenclature\s*$',
            r'^#+\s*glossary\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*glossary\s*$',
            # æ—  # æ ‡è®°çš„æ ¼å¼ï¼ˆæ®µè½å¼€å¤´ï¼‰
            r'^acknowledgements?\s',
            r'^funding\s',
            r'^declarations?\s',
            r'^references?\s',
            r'^appendix\s',
            r'^appendices\s',
            r'^bibliography\s',
            r'^competing\s+interests?\s',
            r'^author\s+contributions?\s',
            r'^data\s+availability\s',
            r'^conflict\s+of\s+interests?\s',
            r'^ethics\s+(statement|declarations?)\s',
            r'^supplementary\s+(materials?|information)\s',
            # ä¸­æ–‡
            r'^#+\s*è‡´è°¢\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*è‡´è°¢\s*$',
            r'^#+\s*å‚è€ƒæ–‡çŒ®\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*å‚è€ƒæ–‡çŒ®\s*$',
            r'^#+\s*é™„å½•\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*é™„å½•\s*$',
            r'^#+\s*èµ„åŠ©\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*èµ„åŠ©\s*$',
            r'^#+\s*åŸºé‡‘\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*åŸºé‡‘\s*$',
            r'^#+\s*åˆ©ç›Šå†²çª\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*åˆ©ç›Šå†²çª\s*$',
            r'^#+\s*ä½œè€…è´¡çŒ®\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*ä½œè€…è´¡çŒ®\s*$',
            r'^#+\s*ä¼¦ç†å£°æ˜\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*ä¼¦ç†å£°æ˜\s*$',
            r'^#+\s*è¡¥å……ææ–™\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*è¡¥å……ææ–™\s*$',
            r'^#+\s*ç¼©ç•¥è¯­\s*$',
            r'^#+\s*\d+[\.ï¼]?\s*ç¼©ç•¥è¯­\s*$',
        ]

        # å®šä¹‰ç« èŠ‚æ¨¡å¼ï¼ˆä½¿ç”¨ re.IGNORECASE æ ‡å¿—ï¼Œæ‰€ä»¥åªéœ€è¦ä¸€ç§å¤§å°å†™å½¢å¼ï¼‰
        section_patterns = {
            'Abstract': [
                r'^#+\s*abstract\s*$',
                r'^abstract\s*:',  # æ—  # æ ‡è®°ï¼ŒAbstract: åè·Ÿå†…å®¹ï¼ˆå¸¦å†’å·ï¼‰
                r'^abstract\s+\S+',  # æ—  # æ ‡è®°ï¼ŒAbstract åç›´æ¥è·Ÿå†…å®¹ï¼ˆæ— å†’å·ï¼‰
                r'^#+\s*æ‘˜è¦\s*$',
                r'^#+\s*a\s*b\s*s\s*t\s*r\s*a\s*c\s*t\s*$',  # å¤„ç†å­—æ¯é—´æœ‰ç©ºæ ¼çš„æƒ…å†µ
                r'^#+\s*summary\s*$',  # Summary
                r'^#+\s*executive\s+summary\s*$',  # Executive Summary
            ],
            'Introduction': [
                # åŸºæœ¬æ ¼å¼
                r'^#+\s*introduction\s*$',
                r'^#+\s*\d+[\.ï¼]?\s*introduction\s*$',  # 1. Introduction æˆ– 1ï¼Introduction
                r'^#+\s*[ivx]+[\.ï¼]?\s*introduction\s*$',  # I. Introduction
                # å¸¸è§å˜ä½“
                r'^#+\s*background\s*$',  # Background
                r'^#+\s*\d+[\.ï¼]?\s*background\s*$',  # 1. Background
                r'^#+\s*motivation\s*$',  # Motivation
                r'^#+\s*\d+[\.ï¼]?\s*motivation\s*$',  # 1. Motivation
                r'^#+\s*overview\s*$',  # Overview
                r'^#+\s*\d+[\.ï¼]?\s*overview\s*$',  # 1. Overview
                r'^#+\s*background\s+and\s+motivation\s*$',  # Background and Motivation
                r'^#+\s*\d+[\.ï¼]?\s*background\s+and\s+motivation\s*$',
                r'^#+\s*related\s+works?\s*$',  # Related Work / Related Works
                r'^#+\s*\d+[\.ï¼]?\s*related\s+works?\s*$',  # 2. Related Work
                r'^#+\s*literature\s+review\s*$',  # Literature Review
                r'^#+\s*\d+[\.ï¼]?\s*literature\s+review\s*$',
                r'^#+\s*background\s+and\s+related\s+works?\s*$',  # Background and Related Work
                r'^#+\s*\d+[\.ï¼]?\s*background\s+and\s+related\s+works?\s*$',
                # æ–°å¢ï¼šæ›´å¤šå¸¸è§è¡¨è¾¾
                r'^#+\s*preliminaries\s*$',  # Preliminariesï¼ˆé¢„å¤‡çŸ¥è¯†ï¼‰
                r'^#+\s*\d+[\.ï¼]?\s*preliminaries\s*$',
                r'^#+\s*problem\s+(statement|formulation|definition)\s*$',  # Problem Statement
                r'^#+\s*\d+[\.ï¼]?\s*problem\s+(statement|formulation|definition)\s*$',
                r'^#+\s*state\s+of\s+the\s+art\s*$',  # State of the Art
                r'^#+\s*\d+[\.ï¼]?\s*state\s+of\s+the\s+art\s*$',
                r'^#+\s*prior\s+works?\s*$',  # Prior Work
                r'^#+\s*\d+[\.ï¼]?\s*prior\s+works?\s*$',
                r'^#+\s*previous\s+works?\s*$',  # Previous Work
                r'^#+\s*\d+[\.ï¼]?\s*previous\s+works?\s*$',
                r'^#+\s*theoretical\s+background\s*$',  # Theoretical Background
                r'^#+\s*\d+[\.ï¼]?\s*theoretical\s+background\s*$',
                r'^#+\s*context\s*$',  # Context
                r'^#+\s*\d+[\.ï¼]?\s*context\s*$',
                r'^#+\s*scope\s*$',  # Scope
                r'^#+\s*\d+[\.ï¼]?\s*scope\s*$',
                r'^#+\s*objectives?\s*$',  # Objective / Objectives
                r'^#+\s*\d+[\.ï¼]?\s*objectives?\s*$',
                r'^#+\s*aims?\s+and\s+objectives?\s*$',  # Aims and Objectives
                r'^#+\s*\d+[\.ï¼]?\s*aims?\s+and\s+objectives?\s*$',
                # ä¸­æ–‡
                r'^#+\s*å¼•è¨€\s*$',
                r'^#+\s*ç»ªè®º\s*$',
                r'^#+\s*å‰è¨€\s*$',
                r'^#+\s*èƒŒæ™¯\s*$',
                r'^#+\s*ç ”ç©¶èƒŒæ™¯\s*$',
                r'^#+\s*ç›¸å…³å·¥ä½œ\s*$',
                r'^#+\s*æ–‡çŒ®ç»¼è¿°\s*$',
                r'^#+\s*é—®é¢˜é™ˆè¿°\s*$',
                r'^#+\s*é—®é¢˜å®šä¹‰\s*$',
                r'^#+\s*ç ”ç©¶ç°çŠ¶\s*$',
                r'^#+\s*ç†è®ºåŸºç¡€\s*$',
                r'^#+\s*é¢„å¤‡çŸ¥è¯†\s*$',
                r'^#+\s*ç ”ç©¶ç›®æ ‡\s*$',
            ],
            'Methods': [
                # åŸºæœ¬æ ¼å¼
                r'^#+\s*methods?\s*$',
                r'^#+\s*\d+[\.ï¼]?\s*methods?\s*$',  # 2. Methods
                r'^#+\s*[ivx]+[\.ï¼]?\s*methods?\s*$',  # II. Methods
                r'^#+\s*methodology\s*$',
                r'^#+\s*\d+[\.ï¼]?\s*methodology\s*$',  # 2. Methodology
                # ææ–™ä¸æ–¹æ³•
                r'^#+\s*materials?\s*$',  # Materialsï¼ˆå•ç‹¬å‡ºç°ä¹Ÿç®—Methodsï¼‰
                r'^#+\s*\d+[\.ï¼]?\s*materials?\s*$',  # 2. Materials
                r'^#+\s*materials?\s+and\s+methods?\s*$',  # Materials and Methods
                r'^#+\s*\d+[\.ï¼]?\s*materials?\s+and\s+methods?\s*$',  # 2. Materials and Methods
                # å®éªŒç›¸å…³
                r'^#+\s*experimental?\s*$',  # Experimental
                r'^#+\s*\d+[\.ï¼]?\s*experimental?\s*$',
                r'^#+\s*experimental\s+(methods?|procedures?|section|setup|design)\s*$',  # Experimental Methods/Setup
                r'^#+\s*\d+[\.ï¼]?\s*experimental\s+(methods?|procedures?|section|setup|design)\s*$',
                r'^#+\s*experiments?\s*$',  # Experiments
                r'^#+\s*\d+[\.ï¼]?\s*experiments?\s*$',
                r'^#+\s*procedures?\s*$',  # Procedure / Procedures
                r'^#+\s*\d+[\.ï¼]?\s*procedures?\s*$',
                # ä»¿çœŸç›¸å…³
                r'^#+\s*simulation\s*$',  # Simulation
                r'^#+\s*\d+[\.ï¼]?\s*simulation\s*$',
                r'^#+\s*simulation\s+(setup|model|framework|environment)\s*$',  # Simulation Setup
                r'^#+\s*\d+[\.ï¼]?\s*simulation\s+(setup|model|framework|environment)\s*$',
                r'^#+\s*numerical\s+(simulation|methods?|analysis)\s*$',  # Numerical Simulation
                r'^#+\s*\d+[\.ï¼]?\s*numerical\s+(simulation|methods?|analysis)\s*$',
                # æ¨¡å‹ç›¸å…³
                r'^#+\s*models?\s*$',  # Model
                r'^#+\s*\d+[\.ï¼]?\s*models?\s*$',
                r'^#+\s*modeling\s*$',  # Modeling
                r'^#+\s*\d+[\.ï¼]?\s*modeling\s*$',
                r'^#+\s*modelling\s*$',  # Modellingï¼ˆè‹±å¼æ‹¼å†™ï¼‰
                r'^#+\s*\d+[\.ï¼]?\s*modelling\s*$',
                r'^#+\s*model\s+(description|formulation|development|construction)\s*$',  # Model Description
                r'^#+\s*\d+[\.ï¼]?\s*model\s+(description|formulation|development|construction)\s*$',
                r'^#+\s*mathematical\s+(model|formulation|framework)\s*$',  # Mathematical Model
                r'^#+\s*\d+[\.ï¼]?\s*mathematical\s+(model|formulation|framework)\s*$',
                r'^#+\s*theoretical\s+(model|framework|formulation)\s*$',  # Theoretical Model
                r'^#+\s*\d+[\.ï¼]?\s*theoretical\s+(model|framework|formulation)\s*$',
                # ç³»ç»Ÿè®¾è®¡ä¸å®ç°
                r'^#+\s*implementation\s*$',  # Implementation
                r'^#+\s*\d+[\.ï¼]?\s*implementation\s*$',
                r'^#+\s*system\s+(design|architecture|implementation|description)\s*$',  # System Design
                r'^#+\s*\d+[\.ï¼]?\s*system\s+(design|architecture|implementation|description)\s*$',
                r'^#+\s*design\s*$',  # Design
                r'^#+\s*\d+[\.ï¼]?\s*design\s*$',
                r'^#+\s*architecture\s*$',  # Architecture
                r'^#+\s*\d+[\.ï¼]?\s*architecture\s*$',
                r'^#+\s*framework\s*$',  # Framework
                r'^#+\s*\d+[\.ï¼]?\s*framework\s*$',
                # ç®—æ³•ä¸æ–¹æ³•
                r'^#+\s*algorithms?\s*$',  # Algorithm
                r'^#+\s*\d+[\.ï¼]?\s*algorithms?\s*$',
                r'^#+\s*approach\s*$',  # Approach
                r'^#+\s*\d+[\.ï¼]?\s*approach\s*$',
                r'^#+\s*proposed\s+(method|approach|algorithm|model|system|framework)\s*$',  # Proposed Method
                r'^#+\s*\d+[\.ï¼]?\s*proposed\s+(method|approach|algorithm|model|system|framework)\s*$',
                r'^#+\s*our\s+(method|approach|algorithm|model|system|framework)\s*$',  # Our Method
                r'^#+\s*\d+[\.ï¼]?\s*our\s+(method|approach|algorithm|model|system|framework)\s*$',
                r'^#+\s*the\s+proposed\s+(method|approach|algorithm|model|system)\s*$',  # The Proposed Method
                r'^#+\s*\d+[\.ï¼]?\s*the\s+proposed\s+(method|approach|algorithm|model|system)\s*$',
                # æŠ€æœ¯ç»†èŠ‚
                r'^#+\s*technical\s+(approach|details|description)\s*$',  # Technical Approach
                r'^#+\s*\d+[\.ï¼]?\s*technical\s+(approach|details|description)\s*$',
                # æ•°æ®ä¸æ ·æœ¬
                r'^#+\s*data\s+(collection|acquisition|preparation|processing)\s*$',  # Data Collection
                r'^#+\s*\d+[\.ï¼]?\s*data\s+(collection|acquisition|preparation|processing)\s*$',
                r'^#+\s*dataset\s*$',  # Dataset
                r'^#+\s*\d+[\.ï¼]?\s*dataset\s*$',
                r'^#+\s*sample\s+(preparation|collection)\s*$',  # Sample Preparation
                r'^#+\s*\d+[\.ï¼]?\s*sample\s+(preparation|collection)\s*$',
                # åˆ†ç±»ã€åˆ†ææ–¹æ³•
                r'^#+\s*classification\s*$',  # Classification
                r'^#+\s*\d+[\.ï¼]?\s*classification\s*$',
                r'^#+\s*formulation\s*$',  # Formulation
                r'^#+\s*\d+[\.ï¼]?\s*formulation\s*$',
                r'^#+\s*problem\s+formulation\s*$',  # Problem Formulation
                r'^#+\s*\d+[\.ï¼]?\s*problem\s+formulation\s*$',
                # è®¡ç®—æ–¹æ³•
                r'^#+\s*computational\s+(methods?|approach|framework)\s*$',  # Computational Methods
                r'^#+\s*\d+[\.ï¼]?\s*computational\s+(methods?|approach|framework)\s*$',
                # ä¸­æ–‡
                r'^#+\s*æ–¹æ³•\s*$',
                r'^#+\s*å®éªŒæ–¹æ³•\s*$',
                r'^#+\s*ç ”ç©¶æ–¹æ³•\s*$',
                r'^#+\s*ææ–™ä¸æ–¹æ³•\s*$',
                r'^#+\s*å®éªŒè®¾è®¡\s*$',
                r'^#+\s*ä»¿çœŸ\s*$',
                r'^#+\s*ä»¿çœŸè®¾è®¡\s*$',
                r'^#+\s*æ•°å€¼ä»¿çœŸ\s*$',
                r'^#+\s*æ¨¡å‹\s*$',
                r'^#+\s*å»ºæ¨¡\s*$',
                r'^#+\s*æ•°å­¦æ¨¡å‹\s*$',
                r'^#+\s*ç†è®ºæ¨¡å‹\s*$',
                r'^#+\s*ç³»ç»Ÿè®¾è®¡\s*$',
                r'^#+\s*ç®—æ³•\s*$',
                r'^#+\s*å®ç°\s*$',
                r'^#+\s*æŠ€æœ¯æ–¹æ¡ˆ\s*$',
                r'^#+\s*æ•°æ®é‡‡é›†\s*$',
                r'^#+\s*æ•°æ®å¤„ç†\s*$',
                r'^#+\s*æ ·æœ¬åˆ¶å¤‡\s*$',
                r'^#+\s*åˆ†ç±»\s*$',
                r'^#+\s*å…¬å¼æ¨å¯¼\s*$',
                r'^#+\s*è®¡ç®—æ–¹æ³•\s*$',
            ],
            'Results & Discussion': [
                # ç»“æœä¸è®¨è®ºåˆå¹¶
                r'^#+\s*results?\s+and\s+discussions?\s*$',  # Results and Discussion
                r'^#+\s*\d+[\.ï¼]?\s*results?\s+and\s+discussions?\s*$',  # 3. Results and Discussion
                r'^#+\s*[ivx]+[\.ï¼]?\s*results?\s+and\s+discussions?\s*$',
                # ç»“æœ
                r'^#+\s*results?\s*$',
                r'^#+\s*\d+[\.ï¼]?\s*results?\s*$',  # 3. Results
                r'^#+\s*[ivx]+[\.ï¼]?\s*results?\s*$',
                r'^#+\s*experimental\s+results?\s*$',  # Experimental Results
                r'^#+\s*\d+[\.ï¼]?\s*experimental\s+results?\s*$',
                r'^#+\s*simulation\s+results?\s*$',  # Simulation Results
                r'^#+\s*\d+[\.ï¼]?\s*simulation\s+results?\s*$',
                r'^#+\s*numerical\s+results?\s*$',  # Numerical Results
                r'^#+\s*\d+[\.ï¼]?\s*numerical\s+results?\s*$',
                r'^#+\s*findings?\s*$',  # Findings
                r'^#+\s*\d+[\.ï¼]?\s*findings?\s*$',
                r'^#+\s*observations?\s*$',  # Observations
                r'^#+\s*\d+[\.ï¼]?\s*observations?\s*$',
                # è®¨è®º
                r'^#+\s*discussions?\s*$',
                r'^#+\s*\d+[\.ï¼]?\s*discussions?\s*$',  # 4. Discussion
                r'^#+\s*[ivx]+[\.ï¼]?\s*discussions?\s*$',
                # è¯„ä¼°ä¸åˆ†æ
                r'^#+\s*evaluation\s*$',  # Evaluation
                r'^#+\s*\d+[\.ï¼]?\s*evaluation\s*$',
                r'^#+\s*performance\s+(evaluation|analysis|assessment)\s*$',  # Performance Evaluation
                r'^#+\s*\d+[\.ï¼]?\s*performance\s+(evaluation|analysis|assessment)\s*$',
                r'^#+\s*analysis\s*$',  # Analysis
                r'^#+\s*\d+[\.ï¼]?\s*analysis\s*$',
                r'^#+\s*experimental\s+(evaluation|analysis)\s*$',  # Experimental Evaluation
                r'^#+\s*\d+[\.ï¼]?\s*experimental\s+(evaluation|analysis)\s*$',
                r'^#+\s*data\s+analysis\s*$',  # Data Analysis
                r'^#+\s*\d+[\.ï¼]?\s*data\s+analysis\s*$',
                r'^#+\s*statistical\s+analysis\s*$',  # Statistical Analysis
                r'^#+\s*\d+[\.ï¼]?\s*statistical\s+analysis\s*$',
                # éªŒè¯ç›¸å…³
                r'^#+\s*verification\s*$',  # Verification
                r'^#+\s*\d+[\.ï¼]?\s*verification\s*$',
                r'^#+\s*validation\s*$',  # Validation
                r'^#+\s*\d+[\.ï¼]?\s*validation\s*$',
                r'^#+\s*model\s+(verification|validation)\s*$',  # Model Verification
                r'^#+\s*\d+[\.ï¼]?\s*model\s+(verification|validation)\s*$',
                r'^#+\s*experimental\s+validation\s*$',  # Experimental Validation
                r'^#+\s*\d+[\.ï¼]?\s*experimental\s+validation\s*$',
                # æ¡ˆä¾‹ç ”ç©¶
                r'^#+\s*case\s+stud(y|ies)\s*$',  # Case Study / Case Studies
                r'^#+\s*\d+[\.ï¼]?\s*case\s+stud(y|ies)\s*$',
                r'^#+\s*application\s*$',  # Application
                r'^#+\s*\d+[\.ï¼]?\s*application\s*$',
                r'^#+\s*applications?\s*$',  # Applications
                r'^#+\s*\d+[\.ï¼]?\s*applications?\s*$',
                # å®éªŒ
                r'^#+\s*experiments?\s*$',  # Experiments
                r'^#+\s*\d+[\.ï¼]?\s*experiments?\s*$',
                # æ¯”è¾ƒ
                r'^#+\s*comparison\s*$',  # Comparison
                r'^#+\s*\d+[\.ï¼]?\s*comparison\s*$',
                r'^#+\s*comparative\s+(analysis|study|evaluation)\s*$',  # Comparative Analysis
                r'^#+\s*\d+[\.ï¼]?\s*comparative\s+(analysis|study|evaluation)\s*$',
                # æ€§èƒ½ç›¸å…³
                r'^#+\s*performance\s*$',  # Performance
                r'^#+\s*\d+[\.ï¼]?\s*performance\s*$',
                r'^#+\s*benchmark\s*$',  # Benchmark
                r'^#+\s*\d+[\.ï¼]?\s*benchmark\s*$',
                r'^#+\s*benchmarking\s*$',  # Benchmarking
                r'^#+\s*\d+[\.ï¼]?\s*benchmarking\s*$',
                # ä¸­æ–‡
                r'^#+\s*ç»“æœ\s*$',
                r'^#+\s*è®¨è®º\s*$',
                r'^#+\s*ç»“æœä¸è®¨è®º\s*$',
                r'^#+\s*å®éªŒç»“æœ\s*$',
                r'^#+\s*ä»¿çœŸç»“æœ\s*$',
                r'^#+\s*æ•°å€¼ç»“æœ\s*$',
                r'^#+\s*åˆ†æ\s*$',
                r'^#+\s*æ€§èƒ½åˆ†æ\s*$',
                r'^#+\s*æ•°æ®åˆ†æ\s*$',
                r'^#+\s*ç»Ÿè®¡åˆ†æ\s*$',
                r'^#+\s*è¯„ä¼°\s*$',
                r'^#+\s*éªŒè¯\s*$',
                r'^#+\s*æ¨¡å‹éªŒè¯\s*$',
                r'^#+\s*å®éªŒéªŒè¯\s*$',
                r'^#+\s*æ¡ˆä¾‹ç ”ç©¶\s*$',
                r'^#+\s*åº”ç”¨\s*$',
                r'^#+\s*æ¯”è¾ƒ\s*$',
                r'^#+\s*å¯¹æ¯”åˆ†æ\s*$',
                r'^#+\s*æ€§èƒ½è¯„ä¼°\s*$',
                r'^#+\s*åŸºå‡†æµ‹è¯•\s*$',
            ],
            'Conclusion': [
                # åŸºæœ¬æ ¼å¼
                r'^#+\s*conclusions?\s*$',  # Conclusion / Conclusions
                r'^#+\s*\d+[\.ï¼]?\s*conclusions?\s*$',  # 4. Conclusions
                r'^#+\s*[ivx]+[\.ï¼]?\s*conclusions?\s*$',  # IV. Conclusions
                # å¸¸è§å˜ä½“
                r'^#+\s*concluding\s+remarks?\s*$',  # Concluding Remarks
                r'^#+\s*\d+[\.ï¼]?\s*concluding\s+remarks?\s*$',
                r'^#+\s*summary\s+and\s+conclusions?\s*$',  # Summary and Conclusions
                r'^#+\s*\d+[\.ï¼]?\s*summary\s+and\s+conclusions?\s*$',
                r'^#+\s*conclusions?\s+and\s+future\s+works?\s*$',  # Conclusions and Future Work
                r'^#+\s*\d+[\.ï¼]?\s*conclusions?\s+and\s+future\s+works?\s*$',
                r'^#+\s*conclusions?\s+and\s+outlook\s*$',  # Conclusions and Outlook
                r'^#+\s*\d+[\.ï¼]?\s*conclusions?\s+and\s+outlook\s*$',
                r'^#+\s*summary\s*$',  # Summary (when used as conclusion)
                r'^#+\s*\d+[\.ï¼]?\s*summary\s*$',
                r'^#+\s*final\s+remarks?\s*$',  # Final Remarks
                r'^#+\s*\d+[\.ï¼]?\s*final\s+remarks?\s*$',
                r'^#+\s*closing\s+remarks?\s*$',  # Closing Remarks
                r'^#+\s*\d+[\.ï¼]?\s*closing\s+remarks?\s*$',
                # æœªæ¥å·¥ä½œ
                r'^#+\s*future\s+works?\s*$',  # Future Work
                r'^#+\s*\d+[\.ï¼]?\s*future\s+works?\s*$',
                r'^#+\s*future\s+(directions?|research|perspectives?)\s*$',  # Future Directions
                r'^#+\s*\d+[\.ï¼]?\s*future\s+(directions?|research|perspectives?)\s*$',
                r'^#+\s*outlook\s*$',  # Outlook
                r'^#+\s*\d+[\.ï¼]?\s*outlook\s*$',
                r'^#+\s*perspectives?\s*$',  # Perspective / Perspectives
                r'^#+\s*\d+[\.ï¼]?\s*perspectives?\s*$',
                # æ€»ç»“ç›¸å…³
                r'^#+\s*summary\s+and\s+future\s+works?\s*$',  # Summary and Future Work
                r'^#+\s*\d+[\.ï¼]?\s*summary\s+and\s+future\s+works?\s*$',
                r'^#+\s*summary\s+and\s+outlook\s*$',  # Summary and Outlook
                r'^#+\s*\d+[\.ï¼]?\s*summary\s+and\s+outlook\s*$',
                # è´¡çŒ®
                r'^#+\s*contributions?\s*$',  # Contribution / Contributions
                r'^#+\s*\d+[\.ï¼]?\s*contributions?\s*$',
                # å½±å“ä¸æ„ä¹‰
                r'^#+\s*implications?\s*$',  # Implications
                r'^#+\s*\d+[\.ï¼]?\s*implications?\s*$',
                # ä¸­æ–‡
                r'^#+\s*ç»“è®º\s*$',
                r'^#+\s*æ€»ç»“\s*$',
                r'^#+\s*ç»“æŸè¯­\s*$',
                r'^#+\s*å±•æœ›\s*$',
                r'^#+\s*æœªæ¥å·¥ä½œ\s*$',
                r'^#+\s*æ€»ç»“ä¸å±•æœ›\s*$',
                r'^#+\s*ç»“è®ºä¸å±•æœ›\s*$',
                r'^#+\s*ç ”ç©¶å±•æœ›\s*$',
                r'^#+\s*æœªæ¥ç ”ç©¶æ–¹å‘\s*$',
                r'^#+\s*æœ¬æ–‡è´¡çŒ®\s*$',
                r'^#+\s*ä¸»è¦è´¡çŒ®\s*$',
            ],
        }

        def get_heading_level(line: str) -> int:
            """
            è·å–æ ‡é¢˜çš„çº§åˆ«
            ä¼˜å…ˆæ ¹æ®ç¼–å·å±‚çº§åˆ¤æ–­ï¼ˆå¦‚ 1. â†’ 1çº§, 2.1. â†’ 2çº§, 3.2.1. â†’ 3çº§ï¼‰
            æ”¯æŒå…¨è§’ç‚¹å·ï¼ˆï¼ï¼‰å’ŒåŠè§’ç‚¹å·ï¼ˆ.ï¼‰
            å¦‚æœæ²¡æœ‰ç¼–å·ï¼Œåˆ™æ ¹æ® # çš„æ•°é‡åˆ¤æ–­
            """
            # å°è¯•åŒ¹é…ç¼–å·æ ¼å¼ï¼ˆå¦‚ 1., 2.1., 3.2.1.ï¼Œæ”¯æŒå…¨è§’ç‚¹ï¼‰
            # åŒæ—¶æ”¯æŒåŠè§’ç‚¹ . å’Œå…¨è§’ç‚¹ ï¼
            # æ”¯æŒç‚¹å·åæœ‰æ— ç©ºæ ¼çš„æƒ…å†µï¼š# 2.1. Title æˆ– # 2.1.Title
            # ä¹Ÿæ”¯æŒæ ‡é¢˜ä¸­æœ‰å…¶ä»–å†…å®¹ï¼š# (xxx) 2.1. Title
            numbering_match = re.search(r'(\d+(?:[\.ï¼]\d+)*)[\.ï¼](?:\s|[A-Za-z])', line)
            if numbering_match:
                # è®¡ç®—ç¼–å·çš„å±‚çº§ï¼ˆç‚¹çš„æ•°é‡ + 1ï¼‰
                numbering = numbering_match.group(1)
                # ç»Ÿä¸€æ›¿æ¢å…¨è§’ç‚¹ä¸ºåŠè§’ç‚¹å†è®¡æ•°
                numbering_normalized = numbering.replace('ï¼', '.')
                level = numbering_normalized.count('.') + 1
                return level
            else:
                # æ ¹æ® # çš„æ•°é‡åˆ¤æ–­
                header_match = re.match(r'^(#+)\s', line)
                if header_match:
                    return len(header_match.group(1))
                return 0

        def get_section_name_for_header(line: str, section_patterns_dict: dict) -> str:
            """
            åˆ¤æ–­ä¸€è¡Œæ ‡é¢˜å±äºå“ªä¸ªä¸»è¦ç« èŠ‚
            è¿”å›ç« èŠ‚åç§°ï¼Œå¦‚æœä¸å±äºä»»ä½•ä¸»è¦ç« èŠ‚åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
            """
            line_stripped = line.strip()
            for sec_name, patterns in section_patterns_dict.items():
                if any(re.match(pattern, line_stripped, re.IGNORECASE) for pattern in patterns):
                    return sec_name
            return ""

        def is_exclude_section(line: str, exclude_patterns_list: list) -> bool:
            """
            åˆ¤æ–­ä¸€è¡Œæ˜¯å¦æ˜¯éœ€è¦æ’é™¤çš„ç« èŠ‚ï¼ˆå¦‚ Acknowledgements, References ç­‰ï¼‰
            è¿”å› True è¡¨ç¤ºæ˜¯æ’é™¤ç« èŠ‚ï¼ŒFalse è¡¨ç¤ºä¸æ˜¯
            """
            line_stripped = line.strip()
            return any(re.match(pattern, line_stripped, re.IGNORECASE) for pattern in exclude_patterns_list)

        # æŸ¥æ‰¾æ¯ä¸ªç« èŠ‚
        for section_name, patterns in section_patterns.items():
            section_start = -1
            section_end = -1
            section_level = 0  # ç« èŠ‚æ ‡é¢˜çš„çº§åˆ«

            # æŸ¥æ‰¾ç« èŠ‚å¼€å§‹
            for i, line in enumerate(lines):
                line_stripped = line.strip()
                if any(re.match(pattern, line_stripped, re.IGNORECASE) for pattern in patterns):
                    section_start = i
                    # è®¡ç®—æ ‡é¢˜çº§åˆ«
                    section_level = get_heading_level(line_stripped)
                    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯æ—  # æ ‡è®°çš„ç« èŠ‚ï¼ˆå¦‚ Abstractï¼‰ï¼Œè®¾ä¸º 1 çº§æ ‡é¢˜
                    if section_level == 0:
                        section_level = 1
                    print(f"    âœ“ æ‰¾åˆ° {section_name}: {line_stripped}")
                    break

            if section_start == -1:
                print(f"    âš ï¸  æœªæ‰¾åˆ° {section_name}")
                continue

            # æŸ¥æ‰¾ç« èŠ‚ç»“æŸï¼ˆä¸‹ä¸€ä¸ªä¸åŒçš„ä¸»è¦ç« èŠ‚çš„æ ‡é¢˜æˆ–æ’é™¤ç« èŠ‚ï¼‰
            for i in range(section_start + 1, len(lines)):
                line_stripped = lines[i].strip()
                
                # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æ’é™¤ç« èŠ‚ï¼ˆæ— è®ºæ˜¯å¦æœ‰ # æ ‡è®°ï¼‰
                if is_exclude_section(line_stripped, exclude_patterns):
                    # é‡åˆ°æ’é™¤ç« èŠ‚ï¼Œç«‹å³ç»“æŸå½“å‰ç« èŠ‚
                    section_end = i
                    print(f"    â“˜ åœ¨æ’é™¤ç« èŠ‚å¤„åœæ­¢: {line_stripped[:50]}...")
                    break
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜ï¼ˆæœ‰ # æ ‡è®°ï¼‰
                if re.match(r'^#+\s', line_stripped):
                    # è·å–å½“å‰æ ‡é¢˜çš„çº§åˆ«
                    current_level = get_heading_level(line_stripped)
                    # å¦‚æœæ˜¯åŒçº§æˆ–æ›´é«˜çº§çš„æ ‡é¢˜
                    if current_level > 0 and current_level <= section_level:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å¦ä¸€ä¸ªä¸åŒçš„ä¸»è¦ç« èŠ‚çš„æ ‡é¢˜
                        matched_section = get_section_name_for_header(line_stripped, section_patterns)
                        if matched_section and matched_section != section_name:
                            # æ˜¯å¦ä¸€ä¸ªä¸»è¦ç« èŠ‚çš„æ ‡é¢˜ï¼Œç»“æŸå½“å‰ç« èŠ‚
                            section_end = i
                            break
                        # å¦‚æœæ˜¯åŒçº§æ ‡é¢˜ä½†ä¸åŒ¹é…ä¸»è¦ç« èŠ‚æ¨¡å¼ï¼š
                        # åªæœ‰å½“å®ƒæ˜¯æ•°å­—ç¼–å·çš„ç« èŠ‚ï¼ˆå¦‚ # 3.ï¼‰æ—¶æ‰ç»“æŸå½“å‰ç« èŠ‚
                        # ï¼ˆé¿å…åƒ # (1) KSlF è¿™æ ·çš„å­æ ‡é¢˜å¯¼è‡´æå‰ç»“æŸï¼‰
                        if current_level == section_level and not matched_section:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—ç¼–å·çš„ç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚ # 3. æˆ– # 3 ï¼‰
                            is_numbered_heading = bool(re.match(r'^#+\s*\d+[\.ï¼]?\s', line_stripped))
                            if is_numbered_heading:
                                # åŒçº§æ•°å­—ç¼–å·æ ‡é¢˜ï¼Œç»“æŸå½“å‰ç« èŠ‚
                                section_end = i
                                print(f"    â“˜ é‡åˆ°åŒçº§æ ‡é¢˜ï¼Œç»“æŸå½“å‰ç« èŠ‚: {line_stripped[:50]}...")
                                break
                            # å¦åˆ™ï¼Œè¿™æ˜¯å½“å‰ç« èŠ‚çš„å­æ ‡é¢˜ï¼ˆå¦‚ # (1) xxxï¼‰ï¼Œç»§ç»­
                        # å¦‚æœæ˜¯å½“å‰ç« èŠ‚çš„å­æ ‡é¢˜æˆ–åŒ¹é…å½“å‰ç« èŠ‚æ¨¡å¼ï¼Œç»§ç»­

            if section_end == -1:
                section_end = len(lines)

            # æå–ç« èŠ‚å†…å®¹
            section_content = '\n'.join(lines[section_start:section_end])
            sections[section_name] = section_content

        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ‰¾åˆ°äº† Results å’Œ Discussionï¼Œåˆå¹¶å®ƒä»¬
        if 'Results' in sections and 'Discussion' in sections:
            sections['Results & Discussion'] = sections['Results'] + '\n\n' + sections['Discussion']
            del sections['Results']
            del sections['Discussion']
            print(f"    âœ“ åˆå¹¶ Results å’Œ Discussion")

        # å¦‚æœéœ€è¦è¿”å›æœªè¯†åˆ«çš„æ ‡é¢˜ï¼Œæ”¶é›†å®ƒä»¬
        if return_unrecognized:
            # éå†æ‰€æœ‰ä¸€çº§æ ‡é¢˜ï¼Œæ‰¾å‡ºæœªè¢«è¯†åˆ«çš„
            for i, line in enumerate(lines):
                line_stripped = line.strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜
                if re.match(r'^#+\s', line_stripped):
                    level = get_heading_level(line_stripped)
                    # åªå…³æ³¨ä¸€çº§æ ‡é¢˜ï¼ˆä¸»è¦ç« èŠ‚ï¼‰
                    if level == 1:
                        # æ£€æŸ¥æ˜¯å¦å·²è¢«è¯†åˆ«
                        matched_section = get_section_name_for_header(line_stripped, section_patterns)
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ’é™¤ç« èŠ‚
                        is_excluded = is_exclude_section(line_stripped, exclude_patterns)
                        # å¦‚æœæ—¢ä¸æ˜¯å·²è¯†åˆ«ç« èŠ‚ï¼Œä¹Ÿä¸æ˜¯æ’é™¤ç« èŠ‚ï¼Œåˆ™è®°å½•ä¸ºæœªè¯†åˆ«
                        if not matched_section and not is_excluded:
                            unrecognized_headers.append((i, line_stripped, level))

            if unrecognized_headers:
                print(f"    â“˜ å‘ç° {len(unrecognized_headers)} ä¸ªæœªè¯†åˆ«çš„ä¸€çº§æ ‡é¢˜")
                for _, header, _ in unrecognized_headers:
                    print(f"       - {header[:60]}...")

        if sections:
            print(f"    âœ… æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•æˆåŠŸæå– {len(sections)} ä¸ªç« èŠ‚")
        else:
            print(f"    âŒ æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•æœªèƒ½æå–ä»»ä½•ç« èŠ‚")

        if return_unrecognized:
            return sections, unrecognized_headers
        else:
            return sections


def load_prompt_template(prompt_file: Path) -> str:
    """
    åŠ è½½æç¤ºè¯æ¨¡æ¿

    Args:
        prompt_file: æç¤ºè¯æ–‡ä»¶è·¯å¾„

    Returns:
        æç¤ºè¯æ¨¡æ¿å­—ç¬¦ä¸²
    """
    if not prompt_file.exists():
        raise FileNotFoundError(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")

    with open(prompt_file, 'r', encoding='utf-8') as f:
        return f.read()


def fix_relative_paths(content: str) -> str:
    """
    ä¿®å¤ç« èŠ‚å†…å®¹ä¸­çš„ç›¸å¯¹è·¯å¾„
    å°† Figure/ æ”¹ä¸º ../Figure/
    å°† Tables/ æ”¹ä¸º ../Tables/

    Args:
        content: ç« èŠ‚å†…å®¹

    Returns:
        ä¿®å¤åçš„å†…å®¹
    """
    import re

    # ä¿®å¤å›¾ç‰‡è·¯å¾„ï¼š![](Figure/xxx) â†’ ![](../Figure/xxx)
    content = re.sub(r'!\[\]\(Figure/', r'![](../Figure/', content)

    # ä¿®å¤è¡¨æ ¼è·¯å¾„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼š![](Tables/xxx) â†’ ![](../Tables/xxx)
    content = re.sub(r'!\[\]\(Tables/', r'![](../Tables/', content)

    return content


def save_sections(sections: Dict[str, str], output_dir: Path) -> List[str]:
    """
    ä¿å­˜æå–çš„ç« èŠ‚åˆ°æ–‡ä»¶

    Args:
        sections: ç« èŠ‚å­—å…¸
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    saved_files = []

    # ç« èŠ‚åç§°æ˜ å°„ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
    section_name_map = {
        "abstract": "Abstract.md",
        "introduction": "Introduction.md",
        "methods": "Methods.md",
        "methodology": "Methods.md",
        "experimental": "Methods.md",
        "materials and methods": "Methods.md",
        "results": "Results & Discussion.md",
        "discussion": "Results & Discussion.md",
        "results and discussion": "Results & Discussion.md",
        "results & discussion": "Results & Discussion.md",
        "conclusion": "Conclusion.md",
        "conclusions": "Conclusion.md",
        "concluding remarks": "Conclusion.md",
        "summary and conclusions": "Conclusion.md",
    }

    # ç”¨äºåˆå¹¶ Results å’Œ Discussion
    results_content = []

    for section_key, content in sections.items():
        if not content or not content.strip():
            continue

        # ä¿®å¤ç›¸å¯¹è·¯å¾„ï¼ˆå›¾ç‰‡ã€è¡¨æ ¼ï¼‰
        content = fix_relative_paths(content)

        # æ ‡å‡†åŒ–ç« èŠ‚åç§°
        section_key_lower = section_key.lower().strip()

        # å¤„ç† Results å’Œ Discussion çš„åˆå¹¶
        if any(key in section_key_lower for key in ["result", "discussion"]):
            # å†…å®¹å·²ç»åŒ…å«æ ‡é¢˜ï¼Œç›´æ¥æ·»åŠ ï¼ˆå¸¦ä¸Šç« èŠ‚ç¼–å·ç”¨äºæ’åºï¼‰
            import re
            # æå–ç¬¬ä¸€ä¸ªæ ‡é¢˜çš„ç¼–å·
            match = re.search(r'^# (\d+)\.', content, re.MULTILINE)
            section_number = int(match.group(1)) if match else 999
            results_content.append((section_number, content))
            continue

        # è·å–æ–‡ä»¶å
        filename = section_name_map.get(section_key_lower, f"{section_key}.md")
        output_file = output_dir / filename

        # ä¿å­˜æ–‡ä»¶ï¼ˆå†…å®¹å·²ç»åŒ…å«æ ‡é¢˜ï¼Œç›´æ¥å†™å…¥ï¼‰
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)

        saved_files.append(str(output_file))

    # ä¿å­˜åˆå¹¶çš„ Results & Discussion
    if results_content:
        # æŒ‰ç« èŠ‚ç¼–å·æ’åº
        results_content.sort(key=lambda x: x[0])
        # åªä¿ç•™å†…å®¹éƒ¨åˆ†
        sorted_content = [content for _, content in results_content]

        output_file = output_dir / "Results & Discussion.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            # ä½¿ç”¨åˆ†éš”ç¬¦è¿æ¥å¤šä¸ªéƒ¨åˆ†
            f.write("\n\n---\n\n".join(sorted_content))
        saved_files.append(str(output_file))

    return saved_files

